name: Test Kubernetes / Helm Install

on:
  pull_request:
    branches:
      - main
      - develop

jobs:
  install-helm-charts:
    runs-on: ubuntu-latest
    services:
      # Runs a local Docker registry accessible at localhost:5000
      registry:
        image: registry:2
        ports:
          - 5000:5000
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Start minikube
        uses: medyagh/setup-minikube@latest

      - name: Install Helm
        run: |
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

      - name: Create Namespace
        run: kubectl create namespace tradestream-namespace

      - name: Create Secrets
        run: |
          kubectl create secret generic \
            coinmarketcap \
            --from-literal=apiKey=FAKE_API_KEY \
            --namespace=tradestream-namespace

      - uses: bazel-contrib/setup-bazel@0.9.1
        with:
          # Avoid downloading Bazel every time
          bazelisk-cache: true
          # Store build cache per workflow
          disk-cache: ${{ github.workflow }}
          # Share repository cache between workflows
          repository-cache: true

      - name: Build and Push the Data Ingestion Image
        run: |
          # Push to local registry
          bazel run //src/main/java/com/verlumen/tradestream/ingestion:push_image \
            --verbose_failures \
            --sandbox_debug \
            -- \
            --repository localhost:5000/tradestream-data-ingestion \
            --tag "latest"

      - name: Build and Push the Strategy Engine Image
        run: |
          # Push to local registry
          bazel run //src/main/java/com/verlumen/tradestream/strategies:push_image \
            --verbose_failures \
            --sandbox_debug \
            -- \
            --repository localhost:5000/tradestream-strategy-engine \
            --tag "latest"

      - name: Pull Images into Local Docker Daemon
        run: |
          # Pull the images from the local registry into the local Docker daemon
          docker pull localhost:5000/tradestream-data-ingestion:latest
          docker pull localhost:5000/tradestream-strategy-engine:latest

          # Retag the images to remove the registry prefix, so Kubernetes doesn't try to pull them remotely
          docker tag localhost:5000/tradestream-data-ingestion:latest tradestream-data-ingestion:latest
          docker tag localhost:5000/tradestream-strategy-engine:latest tradestream-strategy-engine:latest

      - name: Load Images into Minikube
        run: |
          # Load the retagged images into Minikube's image cache
          minikube image load tradestream-data-ingestion:latest
          minikube image load tradestream-strategy-engine:latest

      - name: Install TradeStream Helm Chart
        run: |
          helm dependency update charts/tradestream && \
          helm install my-tradestream charts/tradestream \
            --namespace tradestream-namespace \
            --set strategyEngine.image.repository=tradestream-strategy-engine \
            --set strategyEngine.image.tag=latest \
            --set 'strategyEngine.args[0]=--runMode=dry' \
            --set dataIngestion.image.repository=tradestream-data-ingestion \
            --set dataIngestion.image.tag=latest \
            --set 'dataIngestion.args[0]=--runMode=dry'

      - name: Wait for All Pods to be Ready
        run: |
          set -e  # Exit immediately if a command exits with a non-zero status.

          namespace="tradestream-namespace"
          timeout_seconds=180
          label_selector="${{ github.event.inputs.label_selector }}" # Example of how to get a label selector from a workflow input, default to empty if not set

          echo "Waiting for pods in namespace '${namespace}' to become Ready (timeout: ${timeout_seconds}s)..."

          # Construct the kubectl wait command. Include the label selector if provided.
          wait_command="kubectl wait --for=condition=Ready pod --all -n \"${namespace}\" --timeout=\"${timeout_seconds}s\""
          if [[ -n "${label_selector}" ]]; then
            wait_command="$wait_command -l \"${label_selector}\""
            echo "Using label selector: ${label_selector}"
          fi

          # Execute the kubectl wait command and check for success.
          if ! eval "$wait_command"; then
            echo "Timeout reached or some pods failed to become Ready within ${timeout_seconds} seconds."
            echo -e "\nCurrent pod statuses in namespace '${namespace}':"
            # Use a separate variable for the label flag to improve readability
            label_flag=""
            if [[ -n "${label_selector}" ]]; then
              label_flag="-l \"${label_selector}\""
            fi
            kubectl get pods -n "${namespace}" $label_flag # Use label_flag

            echo -e "\nGathering detailed status and logs for non-ready pods..."

            # This command gets pods where the 'Ready' condition status is 'False'.
            not_ready_pod_names=$(kubectl get pods -n "${namespace}" $label_flag \
              -o 'jsonpath={range .items[?(@.status.conditions[?(@.type=="Ready")].status=="False")]}{.metadata.name}{"\n"}{end}'

            echo -e "\nPods identified as not Ready via JSONPath:\n$not_ready_pod_names" # CHANGED

            if [[ -n "$not_ready_pod_names" ]]; then
              while IFS= read -r pod; do
                echo -e "\nDetails for pod '$pod':"
                kubectl describe pod "$pod" -n "${namespace}"

                # Get detailed status of containers within the pod. # CHANGED
                container_statuses=$(kubectl get pod "$pod" -n "${namespace}" -o go-template='{{range .status.containerStatuses}}{{.name}}={{.state.waiting.reason}}={{.state.terminated.reason}}{{"\n"}}{{end}}')

                containers=$(kubectl get pod "$pod" -n "${namespace}" -o jsonpath='{.spec.containers[*].name}')
                if [[ -n "$containers" ]]; then
                  for container in $containers; do
                    log_this_container=false # Default to not logging unless criteria are met # CHANGED

                    # We are focusing on the pod's Ready condition, not just container states.
                    # Even if a container is "Running", a failing readiness probe means the pod isn't Ready.
                    # We gather logs for all containers in pods that are not Ready.
                    log_this_container=true

                    if "$log_this_container"; then
                      echo -e "\nLogs for container '$container' in pod '$pod':"
                      # We capture both --previous and current logs to provide a more complete picture.
                      # --previous logs can contain information about why a container restarted or failed.
                      kubectl logs "$pod" -n "${namespace}" -c "$container" --previous 2>/dev/null || true # Attempt to get previous logs, ignore errors if not available
                      kubectl logs "$pod" -n "${namespace}" -c "$container"
                    fi
                  done
                else
                  echo "No containers found in pod '$pod'."
                fi
              done <<< "$not_ready_pod_names"
            else
              echo "No pods found that are not in the Ready state."
            fi

            exit 1
          else
            echo "All targeted pods in namespace '${namespace}' are Ready."
          fi
          # We are focusing on the 'Ready' condition of the pods because this indicates
          # whether the application within the pod is ready to serve traffic.
          # A pod can be in the 'Running' phase but still not 'Ready' if its readiness
          # probes are failing.

      - name: Verify Installations
        run: |
          kubectl get pods -n tradestream-namespace
